---
layout: post
title:  "Hessian Ascent for the SK Model"
date:   2024-08-08 11:15:40
blurb: "Optimizing the SK model via free probability and convex duality"
og_image: /assets/img/content/post-example/Banner.jpg
---

[//]: # (<img src="{{ "/assets/img/content/post-example/Banner.jpg" | absolute_url }}" alt="bay" class="post-pic"/>)


Recently, [David](https://davidjekel.com/), [Jonathan](https://www.jshi.science/) and I put out a preprint on the arXiv [(Potential Hessian Ascent: The Sherrington-Kirkpatrick Model, JSS24)](https://arxiv.org/abs/2408.02360). In this post, we will provide the background, motivation, proof structure and main technical innovations of this result, as well as its relationships to other works in the literature and open questions it naturally induces. The goal is to guide a reader about this work (and its ancestor work) and its broader implications and relevance. The post is written for a curious graduate student, but has material (and commentary) that is likely to be of interest to experts as well.

<u>**In a nutshell**:</u> [[JSS24]](https://arxiv.org/abs/2408.02360) introduces and analyzes a Hessian ascent algorithm for the SK model, the update rules of which are motivated (in part) to resolve a conjecture of Eliran Subag [[Sub18, Pg. 8, Ising Spins]](https://arxiv.org/abs/1812.04588). Eliran gave an (essentially) equivalent algorithm for the same models on the sphere. Due to various technical reasons stemming from geometry, the analysis and conceptual understanding for the Hessian ascent algorithm on the cube is significantly more demanding than it is on the sphere.

The main motivations for rigorously developing and analyzing this algorithm are to:
1. Give a conceptually simple algorithm with a purely spectral nature for these models on the cube. Ideally, the algorithm should implement the same principle on the cube that Eliran's algorithm implements on the sphere, leading to a unified principle to optimize (to the conjectured limit for $$\mathsf{poly}(n) $$-time algorithms) random polynomials over _any_ "reasonable" underlying domain $D$.

    The Hessian ascent algorithm designed in this paper demonstrates this is true on the cube, the same way it was on the sphere, with the principle being:
    > Maximize the energy plus the so-called generalized TAP correction  in small, orthogonal increments.

    As it turns out, this generalized TAP correction is a precise measure of entropy, and its derivatives are understood by a particular partial differential equation (which is closely related to the famous Parisi PDE). Deriving and understanding the properties of this PDE, with a starting condition given by the entropy of the Bernoulli-$1/2$ random variable, is critical in a part of the energy analysis for the algorithm.
2. Understand what properties about random polynomials can be efficiently _certified_ using a sum-of-squares hierarchy that [Jonathan](https://www.jshi.science/#Overview) and I introduced in a previous work (see [Sum-of-Squares & Gaussian Processes I: Certification, SS24](https://arxiv.org/abs/2401.14383)). A consequence of the certificates developed in the aforementioned paper is an upper bound on the value that can be reached on an instance of spherical spin-glass problem by, for instance, _any_ randomized algorithm whose output distribution can be captured by a sufficiently "smooth" discrete-time stochastic process that starts at the origin and ends on the sphere. The distributions generated by such processes are termed to be **high-entropy step** (HES) distributions. These certificates give an efficient, algorithmic proof that no HES process can achieve value above a "relaxed" version of the Parisi formula (up to constant factors). Furthermore, a (feasible) process that saturates this value _exists_, and some efficient rounding algorithm should recover it. In the case of the sphere, a straightforwardly randomized version of Subag's Hessian ascent gives a feasible process of this type (see [Algorithm 2, SS24](https://arxiv.org/abs/2401.14383)). The design and analysis of the rounding scheme is delegated to ongoing work ([Sum-of-Squares & Gaussian Processes II: Rounding, SS25]()).

    Conjecturally, we believe the same picture should be true on the cube [[Open Question 1.8, SS24]](https://arxiv.org/abs/2401.14383), and proving this necessitates (in part) the demonstration of the existence of such a process that reaches the conjectured optimal value. In this paper, the Hessian ascent algorithm provides very strong evidence for this. Namely,
    > The covariance matrix at every iterate used to project into the top eigenspace of the TAP-corrected Hessian has bounded operator norm and Frobenius norm, suggesting it is a "smooth" function of the prior iterates. Furthermore, every iterate is sampled from a centered Gaussian with this covariance.

    It is somewhat surprising that such certificates are possible given the strong lower bounds against the standard SoS hierarchy to certify the injective tensor norm of a random tensor; the hierarchy introduced by us circumvents this issue by working with a proof system over a parameterized family of probability measures, rather than working _pointwise_.
3. Ultimately, to give a _principled_ and domain-generalized derivation of the Parisi formula. The Parisi formula was originally derived with non-rigorous physicist methods: the replica trick at the heart of the formula involves writing a combinatorial expression valid for positive integers $k$, then for each $k$ taking its limit as the system size $n$ goes to infinity, and finally taking the continuum limit as $k$ goes to zero... even though the expression was originally only valid for values of $k$ that were integers!
\
In the decades hence, great works of mathematics have proven the Parisi formula true. However, they have accomplished this with a "trapdoor" style of proof: first knowing the form of the Parisi formula, they are able to construct arguments tailored to it---the Ruelle Probability Cascades, for example, are an extremely clever way to generate expected values of the form $$F_{j+1} := \frac{1}{m_j}\log \mathbb{E} e^{F_j}$$... but you would only think to use them after Parisi already wrote down his magical formula involving expressions of that form. Instead, we ultimately seek a principled (and mathematically rigorous) _derivation_ of the Parisi formula over a large set of high-dimensional domains, such that the right algorithm (and algorithmic thresholds) should simply fall out of the clarity of the derivation itself.

#### Table of Contents
1. [The Sherrington-Kirkpatrick Model](#the-sherrington-kirkpatrick-model)
   * [The Parisi formula and Auffinger-Chen Representation](#the-parisi-formula-and-auffinger-chen-representation)
   * [The generalized TAP free energy](#the-generalized-tap-free-energy)
   * [Critical points and the algorithm](#critical-points-and-the-algorithm)
   * [A primal theory for the Parisi PDE via convex duality](#a-primal-theory-for-the-parisi-pde-via-convex-duality)
2. [Proof Sketch](#proof-sketch)
    * [Spectral properties of the TAP-corrected Hessian](#spectral-properties-of-tap-corrected-hessian)
    * [Empirical distribution of the coordinates of the iterates](#empirical-distribution-of-the-coordinates-of-the-iterates)
    * [Fluctuations of the generalized TAP free energy under fRSB](#fluctuations-of-the-generalized-tap-free-energy-under-frsb)
3. [Connections via HES SoS Hierarchy and Geometry](#connections-via-hes-sos-hierarchy-and-geometry)
    * [Unified high-entropy process certificates](#unified-high-entropy-process-certificates)
    * [Generalizing the Parisi theory in primal space](#generalizing-the-parisi-theory-in-primal-space)
4. [Footnotes](#footnotes)
<br>

## The Sherrington-Kirkpatrick Model
We briefly introduce the Sherrington-Kirkpatrick model as an optimization problem. We will be interested in the expected limit of the optimal value, as a standard [gaussian concentration inequality](#gaussian-concentration) implies that the value is extremely concentrated around its expectation. This limit exists almost-surely, and is captured by the famous Parisi formula. This formula has a long history in the statistical physics and probability theory literature (see [Bolthausen's overview of the proof of the Parisi formula]()) that we will not spend much time on in this post. For us, the critical facts are that:
* The Parisi formula is a variational formula over certain measures, and that it is strictly convex over this space having a unique minimizer. Furthermore, one can efficiently find this minimizer since the variational formula is independent of $n$.
* The Parisi formula can be rewritten in terms of an optimal stochastic control problem, and this rewrite is called the Auffinger-Chen representation. It essentially says that the Parisi formula is given by the (expected) value of a function that solves a certain PDE, evaluated at the final point of a _specific_ Ito drift-diffusion process.
* There is (yet another) alternative representation for the Parisi formula which _extends_ into the interior of the solution domain. This quantity, developed rigorously and systematically by Subag [[Sub18]]() for the sphere, and then again by Chen, Panchenko and Subag [[CPS18]]() for the cube  
<br>

### The Parisi formula and Auffinger-Chen Representation

### The generalized TAP free energy

### Critical points and the algorithm

### A primal theory for the Parisi PDE via convex duality

## Proof Sketch

### Spectral properties of the TAP-corrected Hessian

### Empirical distribution of the coordinates of the iterates

### Fluctuations of the generalized TAP free energy under fRSB

## Connections via HES SoS Hierarchy and Geometry

### Unified high-entropy process certificates

### Generalizing the Parisi theory in primal space

#### FOOTNOTES

[^1]: There are many references to this body of work which will be given in due course. Nonetheless, the following two surveys are a nice start: [\[B05\]](http://www.numdam.org/item/SB_2004-2005__47__349_0.pdf), [\[G21\]](https://arxiv.org/pdf/2109.14409.pdf).

[^2]: Stein's Lemma can be proved by a simple integration-by-parts argument for every coordinate $$i $$ in conjunction with Fubini's theorem and the chain-rule. The lemma itself simply asserts that the correlation between a gaussian variable and some function of it is equivalent to a sum of scalings (by the correlations) of the average rate of change of the function. Likewise, Fekete's Lemma boils down to algebraic manipulation of the sequence, where we take the limit infimum of $$x_n/n $$ and compare it to limit infimum of some $$x_m $$ where $$m $$ is chosen to be the supremum as a divisor with a remainder term. The lemma itself merely asserts that for an appropriately growing sequence, the empirical average in the limit simply picks out the largest contributing term.

[^3]: In [this]() upcoming post, various results from the so-called "Gaussian Toolbox" will be stated and briefly proved. This is a very useful set of techniques to have command over in order to prove properties about mean-field spin glasses, and relate them to the behavior of random instances of sparse CSPs.

[^4]: In [this]() upcoming post, we introduce the Guerra-RSB bound and prove that it can be used to show that the Parisi Variaional Principle, represented as an appropriately parameterized RPC, can be used to upper bound the free energy density of the SK model. We will also introduce the famed _Ghirlanda-Guerra_ identities.

[^5]: In [this]() upcoming post, we will introduce some fundamental properties that the RPC tree satisfies, and then derive an alternative representation of the Parisi Variational Principle which can be stated purely as an optimization of a functional whose random measure is supported over the leaves of a RPC tree.
