---
layout: post
title:  "Hessian Ascent for the SK Model"
date:   2024-08-08 11:15:40
blurb: "Optimizing the SK model via free probability and convex duality"
og_image: /assets/img/content/post-example/Banner.jpg
---

[//]: # (<img src="{{ "/assets/img/content/post-example/Banner.jpg" | absolute_url }}" alt="bay" class="post-pic"/>)


Recently, [David](https://davidjekel.com/), [Jonathan](https://www.jshi.science/) and I put out a preprint on the arXiv [(Potential Hessian Ascent: The Sherrington-Kirkpatrick Model, JSS24)](https://arxiv.org/abs/2408.02360). In this post, we will provide the background, motivation, proof structure and main technical innovations of this result, as well as its relationships to other works in the literature and the open questions it naturally induces. The goal is to guide a reader through this work, and a little bit through its ancestor work [[SS24]](https://arxiv.org/abs/2401.14383), focusing on the broader implications of this work and its relevance in the literature. The post is written for a curious graduate student, but has material (and commentary) that is likely to be of interest to experts as well.

**<u>In a nutshell</u>**: [[JSS24]](https://arxiv.org/abs/2408.02360) introduces and analyzes a Hessian ascent algorithm for the SK model, the update rules of which are motivated (in part) to resolve a conjecture of Eliran Subag [[Sub18, Pg. 8, Ising Spins]](https://arxiv.org/abs/1812.04588). Subag gave an (essentially) equivalent algorithm for the same models on the sphere. Due to various technical reasons stemming from geometry, the analysis and conceptual understanding for the Hessian ascent algorithm on the cube is significantly more demanding than it is on the sphere.

At a high-level, the algorithm is fairly simple:
* Set the starting point $$\sigma_0 = (0,\dots,0), $$ and step-size $$\eta = \text{small} $$.
* For $$i \in [K = O(1/\eta)] $$:
    * Set $$Q_i = \text{smooth projector on to top-eigenspace of TAP-corrected Hessian orthogonal to }\sigma_{i-1} $$.
    * Set $$\sigma_i = \sigma_{i-1} + \sqrt{\eta}z $$, where $$z \sim \mathcal{N}(0,Q^2_i) $$.
* Return $$\sigma_K $$ after truncating it and rounding it to $$\{-1,1\}^n $$.

The details of what the "TAP corrected Hessian" of the SK model are will be introduced later, and do not matter for now. The main points are the simplicity of the update rules, and the fact that we are following the top-eigenspace of a certain Hessian matrix induced by the SK model. With this high-level description in hand, we now briefly explain that the main motivations for rigorously developing and analyzing this algorithm are to:
1. <u>Give a conceptually simple and purely spectral algorithm for these models on the cube</u>.

    Ideally, the algorithm should implement the same principle on the cube that Subag's algorithm implements on the sphere, leading to a unified principle to optimize (to the conjectured limit for $$\mathsf{poly}(n) $$-time algorithms) random polynomials over _any_ "reasonable" underlying domain $$D $$.

    The Hessian ascent algorithm designed in this paper accomplishes this on the cube (and resolves Subag's conjecture affirmatively) in the same way it was done on the sphere by Subag, and demonstrates that the universal principle is to:
    > Maximize the objective plus the generalized TAP correction term in small, orthogonal increments starting from the center and eventually ending up at the boundary.

    As it turns out, this generalized TAP correction is a precise measure of entropy, and its derivatives are understood by a particular partial differential equation (which is closely related to the famous Parisi PDE). Deriving and understanding the properties of this PDE, which has an initial condition given by the entropy of the Bernoulli-$$1/2 $$ random variable, is critical in a part of the energy analysis for the algorithm.
2. <u>Understand what properties about random polynomials can be efficiently certified using a sum-of-squares hierarchy that Jonathan and I introduced in a previous work</u> [[SS24]](https://arxiv.org/abs/2401.14383).

    A consequence of the certificates developed in the aforementioned paper is an upper bound on the value that can be reached on an instance of the spherical spin-glass problem by, for instance, _any_ randomized algorithm whose output distribution can be captured by a sufficiently "smooth" discrete-time stochastic process that starts at the origin and ends on the sphere. The distributions generated by such processes are termed to be **high-entropy step** (HES) distributions. Consequently, [[SS24]](https://arxiv.org/abs/2401.14383) actually shows that these certificates give an efficient, algorithmic proof that no HES process can achieve value above a "relaxed" version of the Parisi formula (up to constant factors). Furthermore, a (feasible) HES process that saturates this value _exists_, and some efficient rounding algorithm should recover it. In the case of the sphere, a straightforwardly randomized version of Subag's Hessian ascent gives a feasible process of this type [[Algorithm 2, SS24]](https://arxiv.org/abs/2401.14383). The design and analysis of the rounding scheme is delegated to ongoing work ([Sum-of-Squares & Gaussian Processes II: Rounding, SS25]()).

    Conjecturally, we believe the same picture should be true on the cube [[Open Question 1.8, SS24]](https://arxiv.org/abs/2401.14383), and proving this necessitates (among many other things) the demonstration of a HES process that reaches the conjectured optimal value. In this paper, the Hessian ascent algorithm provides very strong evidence for this. Namely,
    > Every iterate is sampled from a centered Gaussian with covariance $$Q^2_i $$, which has bounded operator norm and Frobenius norm, suggesting it is a "smooth" function of the prior iterates.

    Comparing this with the definition of a HES distribution [[Definition 1.2, SS24]](https://arxiv.org/abs/2401.14383) makes it readily apparent that the update rule of the Hessian ascent algorithm is likely to be captured by a HES process, implying feasibility.

    _<u>Note</u>_: It is somewhat surprising that such certificates are possible given the strong lower bounds against the standard SoS hierarchy to certify the injective tensor norm of a random tensor [[BGL16]](https://arxiv.org/abs/1605.00903); the hierarchy introduced by us circumvents this issue by working with a proof system over a parameterized family of probability measures (HES distributions), rather than working _pointwise_. I will write another blog-post explaining some of the technical contributions of [[SS24]](https://arxiv.org/abs/2401.14383) and how the work motivated (for historical reasons) the current Hessian ascent algorithm on the SK model[^1].

3. <u>Ultimately, give a principled, mathematically rigorous and domain-generalized derivation of the Parisi formula</u>.

    The Parisi formula was originally derived with non-rigorous (but ingenious) methods in statistical physics: the replica trick at the heart of the formula involves writing a combinatorial expression valid for positive integers $$k $$, then for each $$k $$ taking its limit as the system size $$n $$ goes to infinity, and finally taking the continuum limit as $$k $$ goes to zero... even though the expression was originally only valid for values of $$k $$ that were integers!

    In the decades hence, various great works in probability theory and analysis have proven the Parisi formula true. However, they have accomplished this with a "trapdoor" style of proof: first knowing the form of the Parisi formula, they are able to construct arguments tailored to it---the Ruelle Probability Cascades, for example, are an extremely clever way to generate expected values of the form $$F_{j+1} := \frac{1}{m_j}\log \mathbb{E} e^{F_j}$$... but you would only think to use them after Parisi already wrote down his magical formula involving expressions of that form. Instead, we ultimately seek a principled (and mathematically rigorous) _derivation_ of the Parisi formula over a large set of high-dimensional domains, such that the right algorithm (and algorithmic thresholds) should simply fall out of the clarity of the derivation itself.


    The result on the Hessian ascent algorithm for the SK model does not, in and of itself, make any deep progress towards this goal. However, the derivation of the primal Parisi PDE and Auffinger-Chen SDE that ensue in this result give certain hints on how to use geometry to possibly generalize these PDEs to larger domains, and one can imagine that this might lead to a "guess" for generalized Parisi-type formulae.
<br>

#### Table of Contents
1. [The Sherrington-Kirkpatrick Model](#the-sherrington-kirkpatrick-model)
   * [The Parisi formula and Auffinger-Chen Representation](#the-parisi-formula-and-auffinger-chen-representation)
   * [The generalized TAP free energy](#the-generalized-tap-free-energy)
   * [A primal theory for the Parisi PDE via convex duality](#a-primal-theory-for-the-parisi-pde-via-convex-duality)
2. [Proof Sketch](#proof-sketch)
    * [Spectral properties of the TAP-corrected Hessian](#spectral-properties-of-tap-corrected-hessian)
    * [Empirical distribution of the coordinates of the iterates](#empirical-distribution-of-the-coordinates-of-the-iterates)
    * [Fluctuations of the generalized TAP free energy under fRSB](#fluctuations-of-the-generalized-tap-free-energy-under-frsb)
3. [Connections via HES SoS Hierarchy and Geometry](#connections-via-hes-sos-hierarchy-and-geometry)
    * [Unified high-entropy process certificates](#unified-high-entropy-process-certificates)
    * [Generalizing the Parisi theory in primal space](#generalizing-the-parisi-theory-in-primal-space)
4. [Footnotes](#footnotes)
<br>

## The Sherrington-Kirkpatrick Model
We briefly introduce the Sherrington-Kirkpatrick model as an optimization problem. We describe the expected limit of the optimal value, as a standard Gaussian concentration inequality implies that the value is extremely concentrated around its expectation. This limit exists almost-surely, and is captured by the famous Parisi formula at zero temperature. This formula has a long history in the statistical physics and probability theory literature (see [Bolthausen's overview of the proof of the Parisi formula]()) that we will not spend much time on in this post. For us, the critical facts are that:
* The Parisi formula is a variational formula over certain measures, and that it is strictly convex over this space having a unique minimizer. Furthermore, one can efficiently find this minimizer since the variational formula is independent of $$n $$.
* The Parisi formula can be rewritten in terms of an optimal stochastic control problem, and this rewrite is called the Auffinger-Chen representation. It essentially says that the Parisi formula is given by the (expected) value of a function that solves a certain PDE, evaluated over a _specific_ Ito drift-diffusion process, plus a quadratic variation correction term.
* There is (yet) another alternative representation for the Parisi formula which _extends_ into the interior of the solution domain. This quantity, developed rigorously and systematically by Subag [[Sub18]]() for the sphere, and then again by Chen, Panchenko and Subag [[CPS18]]() for the cube, is the heart of the algorithmic design principle mentioned above. In fact, Subag is able to use the ideas related to this representation to give a derivation of the Parisi formula on the sphere (known as the Crisanti-Sommers formula) from _first principles_. Unfortunately, this is (seemingly) not quite yet in reach for the cube. Nonetheless, there is remarkable structural similarity between the generalized TAP equation on the sphere and the cube in terms of its component terms, and this is enough to demonstrate how Subag's conjecture about step-wise optimization on the cube and our resolution of it follow naturally from this equation.

### The Parisi formula and Auffinger-Chen Representation
The Parisi formula was proposed by Giorgio Parisi in 1979 to give the asymptotic free energy density of the Sherrington-Kirkpatrick (SK) model. It was first rigorously proved in a series of works by Guerra and Talagrand, the culmination of which was in the hard direction of the proof by Talagrand. The model is given by the following cost function,

$$ \begin{equation} H(\sigma) = \langle \sigma, A\sigma\rangle\,,\end{equation}$$

where $$A $$ is a random matrix with i.i.d. $$\mathcal{N}(0,1/n) $$ entries. It can be shown by standard concentration arguments for Lipschitz functions of Gaussians that the maximum value of this cost function is concentrated around $$\mathbb{E}[\max_{\sigma \in \{-1,1\}^n}H(\sigma)] $$. The expected value is given by the zero-temperature limit of the famous Parisi formula. The Parisi formula for the SK model at inverse temperature $$\beta = 1/T $$ is given by,

$$ \begin{equation} P_\beta(\mu) = \Phi_\mu(0,0) - \beta^2\int_0^1t\mu(t)dt\,,\end{equation} $$

where $$\mu(.) $$ is a cumulative-distribution function for a probability measure with support in $$[0,1] $$ and $$\Phi_\mu $$ is the solution to the following parabolic PDE,

$$ \begin{equation} \partial_t \Phi_\mu(t,x) + \beta^2\left(\partial_{xx} \Phi(t,x) + \mu(t)(\partial_x \Phi(t,x))^2\right)= 0\,,\end{equation}$$

with initial condition $$\Phi(1,x) = \log(2\cosh(x)) $$. Various properties about the solutions of this equation, and a zero temperature variant of it, are known. The main two points for a reader of this post about this PDE are:
1. Its solution exists, is well-posed, and has various pleasant regularity properties: namely, the spatial derivatives are Lipschitz, and the mixed derivatives have regularity depending on the properties of $$\mu $$.
2. $$\Phi $$ is actually the Fenchel-Legendre (FL) dual (in $$x $$) of an entropic function, and the initial condition $$\Phi(1,x) $$ in particular is the FL dual of the Bernoulli-$$1/2 $$ entropy.

These observations suggest that, somehow, the Parisi formula is rewriting the (asymptotic) free energy density of the SK model in terms of an entropy term and an internal energy term. This intuition is made more precise (and clear) in the generalized TAP representation. The relevance of the Parisi PDE stems from point 2. above, since the FL dual to $$\Phi $$ shows up in the generalized TAP correction term. Consequently, in the analysis of the Hessian ascent algorithm, there is a need to:
1. Understand the time derivative of the FL dual to $$\Phi $$ at various points.

Doing this requires getting a Parisi-like PDE, but in the space _dual_ to $$x $$. For technical reasons, this requires writing a PDE in this dual space, but for a FL dual for a function $$\Phi_\gamma $$ which is a "smoothening" of $$\Phi $$.

We will revisit this point in the [1.3](#a-primal-theory-for-the-parisi-pde-via-convex-duality). For now, we just conclude by precisely stating how the Parisi formula gives the limiting optimal value for our Hamiltonian of interest:

$$ \begin{equation} \lim_{n \to \infty}\frac{1}{n}\mathbb{E}\left[\max_{\sigma \in \{-1,1\}^n} H(\sigma)\right] = \lim_{\beta \to \infty} \frac{1}{\beta} \inf_{\mu} P_\beta(\mu)\,. \end{equation} $$

As it turns out, getting a "dual" version of the Parisi PDE is not quite sufficient. In fact, in the analysis of the Hessian ascent algorithm, there is also a need to:
1. Explicitly analyze the expected value (under the algorithm's randomness) of the FL dual to $$\Phi(t,X_t) $$ where $$t = q^*_\beta $$, such that $$q^*_\beta \to 1 $$ sufficiently fast as $$\beta \to \infty $$ , and
2. Demonstrate that, with high probability over the input and algorithm's randomness, the diagonal matrix $$D(t,\sigma) $$ corresponding to the Hessian of the TAP-correction term satisfies (under the fRSB condition[^2]) the equality

$$ \begin{equation} 2\beta^2 \frac{1}{n}\mathsf{Tr}[D(t,\sigma)^{-2}] = 1\,.\end{equation} $$

To successfully deal with the two points mentioned above, we need a _stochastic control_ reformulation of (the FL dual to) $$\Phi $$. Using the SDE underlying this representation, the computation of the quantity in the first point is made tractable, and demonstrating that the second point is true requires showing that the empirical distribution of the coordinates of every iterate of the algorithm converge to the SDE that underlies this reformulation.

For $$\Phi $$ itself, this reformulation as a _stochastic optimal control_ problem is known as the **Auffinger-Chen representation**, and it gives a rewrite for the Parisi PDE. More specifically, if $$\Phi $$ is a solution to the Parisi PDE, then,

$$ \begin{equation} \Phi(0,x) = \max_{\{X_s\}_{0 \le s \le 1}}\left(\mathbb{E}\left[\Phi\left(1, x + 2\beta\int_0^1\mu(s)X_s ds + \sqrt{2}\beta z\right) - \beta^2\int_0^1\mu(s)\mathbb{E}[X^2_s]ds\right]\right)\, ,\end{equation} $$

where $$z \sim \mathcal{N}(0,1) $$, and the maximizer of the above is unique and given by the strong solution to the following Ito drift-diffusion process,

$$ \begin{equation} dX_s = 2\beta^2 \mu(t)\partial_x \Phi(s,X_s)ds + \sqrt{2}\beta dW_s\,, \,\,\, X_0 = 0\,. \end{equation}$$

In fact, as hinted at above, we will need to write down a new SDE corresponding to the one above that runs in the "dual" space, where the iterates of our Hessian ascent algorithm reside. This is born directly out of the fact that the quantities in the generalized TAP correction correspond to the FL dual of the solution to the Parisi PDE. With the "dual" SDE (introduced with the "dual" Parisi-like PDE in the final subsection of this section) in hand, we can use some Ito calculus to compute the first quantity, and, use convergence of the empirical distribution of the coordinates of every iterate of the Hessian ascent algorithm (whp) in Wasserstein distance to the "dual" version of the AC SDE to obtain the second statement.

It is reasonable to wonder why I have put quotations around the word _dual_ in every invocation so far: this is because, in fact, the iterates of the Hessian ascent algorithm are actually (after truncation) in the _primal_ space (which is $$[-1,1]^n $$) and, somewhat mysteriously, it is the Parisi PDE and AC SDE that are in the _dual_ space. Some clarification about this is afforded in a recent paper by Mouratt [[Mou23]](https://arxiv.org/abs/2308.10715).

This is perhaps one reason why the approximate-message passing (AMP) algorithms previously used to optimize these problems are somewhat opqaue to a particularly neat conceptual interpretation: the iterates $$\{u_k\}_{k} $$ of the AMP algorithm [[Mon19]](https://arxiv.org/abs/1812.10897) are updated by discretizing the AC SDE, taking a single step of the discretized SDE, then updating the current iterate by multiplying the Hessian of the objective with a non-linearity evaluated at this new step rescaled by the current iterate value coordinatewise, and finally correcting the whole computation by subtracting a term known as the _Onsager correction_. Upon running these complicated updates for a sufficient number of iterations, these iterates are then again rescaled (by a small parameter $$\sqrt{\delta} $$) and transformed (yet) again (non-linearly) into the _primal_ space, where the iterates are truncated and rounded onto the hypercube. <br>
Au contraire, as we saw, the Hessian ascent algorithm remains _squarely_ in the primal space, leading to a very simple update rule as well as a very clean conceptual interpretation a-la Subag's principle mentioned in the introduction.

### The generalized TAP free energy
In the previous subsection, we introduced the Parisi formula, the Auffinger-Chen representation, and mentioned how they work in a dual space. We then stated that, given the fact that the TAP correction involves a FL dual to the solution of the Parisi PDE, for various reasons in the analysis of the Hessian ascent algorithm, we will need to develop a primal version of the Parisi PDE and AC SDE.

We now table the development of this _primal_ PDE and SDE to the last subsection, and first write down the form of the generalized TAP free energy on the cube introduced in [[CPS18]](https://arxiv.org/abs/1812.05066v2). We will briefly interpret the generalized TAP correction and write down its gradient at a critical point, yielding the generalized TAP equation. Then, observe that jumping from one critical point (where the gradient is $$0 $$) to the next entails moving along the _kernel_ of the _Hessian_ of the generalized TAP free energy. It will turn out that, in order to move along a path of critical points of the generalized TAP equation by moving into this kernel, one will automatically be forced to climb the top-eigenspace of,

$$ \begin{equation} \nabla^2\bigg(\langle \sigma, A \sigma\rangle - \text{FL dual to }\Phi(t,x)\bigg) = A - \nabla^2\left(\text{FL dual to }\Phi(t,x)\right)\, .\end{equation} $$

For largely historical reasons[^3] we will use a _convex_ dual, while [[CPS18]](https://arxiv.org/abs/1812.05066v2) use a _concave_ dual to define the generalized TAP free energy correction term. Let us begin by defining the FL dual to the solution $$\Phi $$ of the Parisi PDE,

$$\begin{equation} \Lambda(t,y) = \sup_{x \in \mathbb{R}}\left(xy - \Phi(t,x)\right) \end{equation}\,, $$

for every $$t \in [0, 1] $$. It is well known that $$\Phi $$ is strictly convex in $$x $$ [[Section 2, CPS18]](https://arxiv.org/abs/1812.05066v2), and using this it is not hard to ascertain the following facts:
* The maximizer of the FL dual is unique for every $$y \in [-1,1] $$ and obeys the relationship $$y = \partial_x \Phi(t,x) $$.
* In fact, the maps $$y = \partial_x \Phi(t,x) $$ and $$x = \partial_y \Lambda(t,y) $$ define a change of coordinates from $$\mathbb{R} \to \{-1,1\} $$ and vice-versa. There are two points to notice here:
    * The derivatives of $$\Phi $$ and $$\Lambda $$ are maps that take us between (convexly) dual spaces. While the generalized TAP energy, involving $$\Lambda $$ stays in the primal space, the standard Parisi machinery is in the dual space. This implies that, beneath the entire framework, there is some unifying principle of convex geometry at work.
    * They are inverse functions of each other, except for some minor issues that arise on the corners where $$\Lambda = \Phi^{-1} $$ blows up. To overcome this, a regularization to the FL dual is introduced (see [[Section 2, SS24]]() and [1.3]()). In fact, the algorithm actually follows this _regularized_ FL dual that has desirable smoothness properties around the corners of the cube. As we shall see, we will demonstrate (in [1.3]()) that this regualized FL dual stays uniformly close to $$\Lambda $$ inside the cube, and is negligible outside, meaning the errors introduced are manageable.

The use of the convex dual actually ends up being convenient, because at a critical point $$\sigma $$,

$$ \begin{equation} \frac{1}{n}\nabla H(\sigma) = -\nabla\mathsf{TAP}(\sigma)\,, \end{equation} $$

and our choice of FL dual gives the following form for the TAP correction term,

$$ \begin{equation} \mathsf{TAP}_{\text{emp}}(\sigma) = -\int \Lambda(t,\sigma) d(\text{emp}(\sigma)) - \beta^2\int_{\frac{1}{n}\|\sigma\|^2_2}^1 t\mu(t)dt\, , \end{equation} $$

analogous to what is given in [[Eq. 1.27, CPS18]](https://arxiv.org/abs/1812.05066v2). The generalized TAP equation for mean-field spin glasses on the cube is introduced in [[Theorem 2, CPS18]](https://arxiv.org/abs/1812.05066v2). Using the explicit representation of the generalized TAP equation along with the facts about the FL duals above, some calculus yields that the critical points $$\sigma $$ satisfy the following eigenvector equation,

$$ \begin{equation}  \left(\beta A - \left(2\beta^2\int_q^1 \mu(t)dt\right)\mathsf{Id}\right)\sigma = \left(\partial_{\sigma_1}\Lambda(q,\sigma_1),\dots,\partial_{\sigma_n}\Lambda(q,\sigma_n)\right)\,, \end{equation} $$

where $$q = \frac{1}{n}\|\sigma\|^2_2 $$. The representation above is equivalent to [[Remark 6, CPS18]](). Now comes the critical part: We would like to have an algorithm that follows small (orthogonal) updates, such that, _every_ point is a critical point along the path. This means that we _must_ actually proceed in a direction where the Hessian of the TAP equation (projected orthogonal to the current location) is zero. Equivalently, we must stay in the kernel of the Hessian projected orthogonal to the current iterate.

After taking the gradient of the above equation, applying chain rule, using the FL duality rewrites, and discarding terms that are rank-$$1 $$ or along the current iterate ($$\sigma $$), we arrive that the Hessian must satisfy the following condition,

$$ \begin{equation} 2\beta A_{\text{sym}} - \sum_{i} \partial_{\sigma_i\sigma_i}\Lambda(q,\sigma_i) e_ie_i^{\mathsf{T}} - \frac{2\beta^2}{n}\sum_{i \in [n]}\partial_{x_ix_i}\Phi(q,x_i)\mathsf{Id} = 0\end{equation}\,, $$

where $$A_{\text{sym}} = (A + A^{\mathsf{T}})/2 $$ is distributed as $$\sqrt{2}\,\mathsf{GOE}(n) $$. Therefore, _if_ we are at a critical point $$\sigma $$ and we wish to make a small $$\approx \eta $$ sized increment that jumps to the next TAP state (critical point), it is critical that the quadratic form with the matrix in the Hessian term above be (approximately) $$0 $$. This basically implies that we want to take states in the eigenspace of

$$ \begin{equation} 2\beta A_{\text{sym}} - D(q,\sigma) \end{equation} $$

with value

$$ \begin{equation} \approx \frac{2\beta^2}{n}\sum_i \partial_{x_ix_i}\Phi(q,x_i) = \frac{2\beta^2}{n}\mathsf{Tr}[D^{-1}(q,\sigma)]\, , \end{equation}$$

where we use the fact that whenever $$\partial_{xx}\Phi(t,x) > 0 $$, its reciprocal is well-defined and equal to $$\partial_{yy} \Lambda(t,y) $$ when $$x $$ and $$y $$ satisfy the change of coordinates implied by FL duality (that is, they are critical points in their respective bases). This identity is called the [Crouzeix identity in convex analysis](), and is an important observation in working out the details of the primal Parisi theory ([1.3]())  as well as understanding the conceptual basis on which the free-probabilistic analysis of the Hessian proceeds.

As it turns out, the desired value will be the top-part of the TAP corrected Hessian (see [2.1]()) and, therefore, we will need an inductive argument, where we can construct a covariance matrix $$Q^2(\sigma) $$ matrix for $$Q(\sigma) $$, which smoothly projects into the top eigenspace of,

$$ \begin{equation} \text{TAP-corrected Hessian} = 2\beta A_{\text{sym}} - D(q,\sigma) \overset{d}{=} \sqrt{2}\beta\,\mathsf{GOE}(n) - D(q,\sigma)\,. \end{equation} $$

We _will_ be able to accomplish this, _conditioned_ on the fact that,

$$ \begin{equation} \frac{2\beta^2}{n}\mathsf{Tr}[D^{-2}(q,\sigma)] = 1\, \end{equation} $$,

which will in-turn require that $$\sigma $$ be a critical point. This will, further, require that the empirical ditribution of the coordinates of $$\sigma $$ behave like the AC SDE in _primal_ space. Proving this will require the assumption of fRSB, along with the last step being taken in the direction of the top-eigenspace of the TAP-corrected Hessian, and so on and so forth.

Therefore, we will set up an inductive argument, where the first step will go along the direction of the top-eigenspace of the Hessian orthogonal to the all-$$0 $$ vector (which means there is no restriction) and since the primal version of the AC SDE starts at $$0 $$, it will trivially satsify the identity required.

After this, in [2.2](), we will show that given the choice of the iterate coming from an (appropriately rescaled) eigenvector in the top-eigenspace of the TAP-corrected Hessian, the empirical distribution of the coordinates of its iterates will converge (in Wasserstein-$$2 $$ distance) to the _primal_ version of the AC SDE (with high probability).

### A primal theory for the Parisi PDE via convex duality

## Proof Sketch

### Spectral properties of the TAP-corrected Hessian

### Empirical distribution of the coordinates of the iterates

### Fluctuations of the generalized TAP free energy under fRSB

## Connections via HES SoS Hierarchy and Geometry

### Unified high-entropy process certificates

### Generalizing the Parisi theory in primal space

#### FOOTNOTES

[^1]: The main contribution of [[SS24]]() is the introduction of a new hierarchy over HES processes, and the hierarchy is termed the HES SoS hierarchy. The reason for choosing these processes is many-fold, and is explained in the paper's introduction. However, in large part, this paper was born out of the desire to understand what exactly made the _search_ problem of finding near-optima of spin-glasses significantly easier than the _certification_ problem.

[^2]: The fRSB condition is an imposition on the support of the probability measure $$\mu $$ that optimizes the Parisi formula $$P_\beta(\mu) $$. It states that the density associated with $$\mu $$ is fully-supported in a sub-interval $$[0, q^*_\beta] $$. Equivalently, $$\mu $$ is strictly increasing in $$[0, q^*_\beta] $$.

[^3]: When Jonathan and I were working on the project in the early days, we were thinking of this convex duality via the lens of mirror maps. It turns out that, because of the underlying convex duality, there is a connection to be made here through the information geometry of the underlying Hessian being akin to a (flat) Bregmannian manifold. However, this is beyond the scope of this post and something we are investigating in ongoing work.

[^4]: In [this]() upcoming post, we introduce the Guerra-RSB bound and prove that it can be used to show that the Parisi Variaional Principle, represented as an appropriately parameterized RPC, can be used to upper bound the free energy density of the SK model. We will also introduce the famed _Ghirlanda-Guerra_ identities.

[^5]: In [this]() upcoming post, we will introduce some fundamental properties that the RPC tree satisfies, and then derive an alternative representation of the Parisi Variational Principle which can be stated purely as an optimization of a functional whose random measure is supported over the leaves of a RPC tree.
